<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.6.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=description content="The comprehensive evaluation of the performance of a recommender system is a complex endeavor: many facets need to be considered in configuring an adequate and effective evaluation setting. Such facets include, for instance, defining the specific goals of the evaluation, choosing an evaluation method, underlying data, and suitable evaluation metrics. In this paper, we consolidate and systematically organize this dispersed knowledge on recommender systems evaluation. We introduce the “Framework for EValuating Recommender systems” (FEVR) that we derive from the discourse on recommender systems evaluation. In FEVR, we categorize the evaluation space of recommender systems evaluation. We postulate that the comprehensive evaluation of a recommender system frequently requires considering multiple facets and perspectives in the evaluation. The FEVR framework provides a structured foundation to adopt adequate evaluation configurations that encompass this required multi-facettedness and provides the basis to advance in the field. We outline and discuss the challenges of a comprehensive evaluation of recommender systems, and provide an outlook on what we need to embrace and do to move forward as a research community."><link rel=alternate hreflang=en-us href=http://multimethods.github.io/publication/zangerle-2022-fevr/><meta name=theme-color content="#bbdefb"><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.e7362a20929d7135d3069073b797461b.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"' disabled><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"'><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hubeba305db54ae0fb80d3f2bbde458477_2712_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hubeba305db54ae0fb80d3f2bbde458477_2712_180x180_fill_lanczos_center_3.png><link rel=canonical href=http://multimethods.github.io/publication/zangerle-2022-fevr/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="multimethods.info"><meta property="og:url" content="http://multimethods.github.io/publication/zangerle-2022-fevr/"><meta property="og:title" content="Evaluating Recommender Systems: Survey and Framework | multimethods.info"><meta property="og:description" content="The comprehensive evaluation of the performance of a recommender system is a complex endeavor: many facets need to be considered in configuring an adequate and effective evaluation setting. Such facets include, for instance, defining the specific goals of the evaluation, choosing an evaluation method, underlying data, and suitable evaluation metrics. In this paper, we consolidate and systematically organize this dispersed knowledge on recommender systems evaluation. We introduce the “Framework for EValuating Recommender systems” (FEVR) that we derive from the discourse on recommender systems evaluation. In FEVR, we categorize the evaluation space of recommender systems evaluation. We postulate that the comprehensive evaluation of a recommender system frequently requires considering multiple facets and perspectives in the evaluation. The FEVR framework provides a structured foundation to adopt adequate evaluation configurations that encompass this required multi-facettedness and provides the basis to advance in the field. We outline and discuss the challenges of a comprehensive evaluation of recommender systems, and provide an outlook on what we need to embrace and do to move forward as a research community."><meta property="og:image" content="http://multimethods.github.io/publication/zangerle-2022-fevr/fevr_featured.png"><meta property="twitter:image" content="http://multimethods.github.io/publication/zangerle-2022-fevr/fevr_featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2022-08-19T01:13:45+00:00"><meta property="article:modified_time" content="2023-01-22T03:11:11+02:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"http://multimethods.github.io/publication/zangerle-2022-fevr/"},"headline":"Evaluating Recommender Systems: Survey and Framework","image":["http://multimethods.github.io/publication/zangerle-2022-fevr/fevr_featured.png"],"datePublished":"2022-08-19T01:13:45Z","dateModified":"2023-01-22T03:11:11+02:00","author":{"@type":"Person","name":"Eva Zangerle"},"publisher":{"@type":"Organization","name":"multimethods.info","logo":{"@type":"ImageObject","url":"http://multimethods.github.io/media/icon_hubeba305db54ae0fb80d3f2bbde458477_2712_192x192_fill_lanczos_center_3.png"}},"description":"The comprehensive evaluation of the performance of a recommender system is a complex endeavor: many facets need to be considered in configuring an adequate and effective evaluation setting. Such facets include, for instance, defining the specific goals of the evaluation, choosing an evaluation method, underlying data, and suitable evaluation metrics. In this paper, we consolidate and systematically organize this dispersed knowledge on recommender systems evaluation. We introduce the “Framework for EValuating Recommender systems” (FEVR) that we derive from the discourse on recommender systems evaluation. In FEVR, we categorize the evaluation space of recommender systems evaluation. We postulate that the comprehensive evaluation of a recommender system frequently requires considering multiple facets and perspectives in the evaluation. The FEVR framework provides a structured foundation to adopt adequate evaluation configurations that encompass this required multi-facettedness and provides the basis to advance in the field. We outline and discuss the challenges of a comprehensive evaluation of recommender systems, and provide an outlook on what we need to embrace and do to move forward as a research community."}</script><title>Evaluating Recommender Systems: Survey and Framework | multimethods.info</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class="page-wrapper dark" data-wc-page-id=d150707f6006da50e4a289c6af06027b><script src=/js/wowchemy-init.min.be7f978347a4a9d127abba3b034288c9.js></script><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>multimethods.info</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>multimethods.info</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/#about><span>About</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#events><span>Events</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Evaluating Recommender Systems: Survey and Framework</h1><div class=article-metadata><div><span><a href=/author/eva-zangerle/>Eva Zangerle</a></span>, <span><a href=/author/christine-bauer/>Christine Bauer</a></span></div><span class=article-date>August 2022</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=/publication/zangerle-2022-fevr/zangerle-2022-fevr.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/zangerle-2022-fevr/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header" href=https://doi.org/10.1145/3556536 target=_blank rel=noopener>DOI</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:369px><div style=position:relative><img src=/publication/zangerle-2022-fevr/fevr_featured_hu9607a67cdb015e3f74deb12fceaf78b2_578591_720x2500_fit_q75_h2_lanczos_3.webp width=720 height=369 alt class=featured-image>
<span class=article-header-caption>Framework for EValuating Recommender systems (FEVR)</span></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>The comprehensive evaluation of the performance of a recommender system is a complex endeavor: many facets need to be considered in configuring an adequate and effective evaluation setting. Such facets include, for instance, defining the specific goals of the evaluation, choosing an evaluation method, underlying data, and suitable evaluation metrics. In this paper, we consolidate and systematically organize this dispersed knowledge on recommender systems evaluation. We introduce the “Framework for EValuating Recommender systems” (FEVR) that we derive from the discourse on recommender systems evaluation. In FEVR, we categorize the evaluation space of recommender systems evaluation. We postulate that the comprehensive evaluation of a recommender system frequently requires considering multiple facets and perspectives in the evaluation. The FEVR framework provides a structured foundation to adopt adequate evaluation configurations that encompass this required multi-facettedness and provides the basis to advance in the field. We outline and discuss the challenges of a comprehensive evaluation of recommender systems, and provide an outlook on what we need to embrace and do to move forward as a research community.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#2>Journal article</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9"><em>ACM Computing Surveys</em></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/evaluation/>evaluation</a>
<a class="badge badge-light" href=/tag/recommender-systems/>recommender systems</a>
<a class="badge badge-light" href=/tag/fevr/>FEVR</a>
<a class="badge badge-light" href=/tag/survey/>survey</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=http%3A%2F%2Fmultimethods.github.io%2Fpublication%2Fzangerle-2022-fevr%2F&text=Evaluating+Recommender+Systems%3A+Survey+and+Framework" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Fmultimethods.github.io%2Fpublication%2Fzangerle-2022-fevr%2F&t=Evaluating+Recommender+Systems%3A+Survey+and+Framework" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Evaluating%20Recommender%20Systems%3A%20Survey%20and%20Framework&body=http%3A%2F%2Fmultimethods.github.io%2Fpublication%2Fzangerle-2022-fevr%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=http%3A%2F%2Fmultimethods.github.io%2Fpublication%2Fzangerle-2022-fevr%2F&title=Evaluating+Recommender+Systems%3A+Survey+and+Framework" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Evaluating+Recommender+Systems%3A+Survey+and+Framework%20http%3A%2F%2Fmultimethods.github.io%2Fpublication%2Fzangerle-2022-fevr%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=http%3A%2F%2Fmultimethods.github.io%2Fpublication%2Fzangerle-2022-fevr%2F&title=Evaluating+Recommender+Systems%3A+Survey+and+Framework" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></div></div><div class=page-footer><div class=container><div style=font-size:14px;text-align:center>Site powered by <a href=https://gohugo.io/>Hugo</a>, using the <a href=https://themes.gohugo.io/academic/>Academic</a> theme.</div></div></div><script src=/js/vendor-bundle.min.92d2024afaa4dce0cad42ba360879ce9.js></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.e8fd2d733eef6a8bbbe0539398fc0547.js type=module></script>
<script src=/en/js/wowchemy.min.4c1eb225e491dbd0a230aeb7c6f7bad6.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>