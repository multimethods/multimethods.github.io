---
# Documentation: https://wowchemy.com/docs/managing-content/
type: publication

title: Multi-method evaluation of adaptive systems
subtitle: ''
summary: ''
authors:
- Christine Bauer
tags: [evaluation, multimethod, adaptive systems, personalization, recommender systems]
categories: []
date: 2021-06-21 #21-25 June
lastmod: 2021-08-08T03:11:12+02:00
featured: false
draft: false
profile: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false


projects: []
publishDate: '2021-08-08T01:13:46.692755Z'
publication_types: [paper-conference]
publication: '*29th Conference on User Modeling, Adaptation and Personalization*'
publication_short: UMAP 2021

abstract: 'When evaluating personalized or adaptive systems, we frequently rely on one single evaluation objective and one single method. This remains us with “blind spots”. A comprehensive evaluation may require a thoughtful integration of multiple methods. This tutorial (i) demonstrates the wide variety of dimensions to be eval- uated, (ii) outlines the methodological approaches to evaluate these dimensions, (iii) pinpoints the blind spots when using only one ap- proach, (iv) demonstrates the benefits of multi-method evaluation, and (v) outlines the basic options how multiple methods can be integrated into one evaluation design. Participants familiarize with the wide spectrum of opportunities how adaptive or personalized systems may be evaluated, and have the opportunity to come up with evaluation designs that comply with the four basic options of multi-method evaluation. The ultimate learning objective is to stimulate the critical reflection of one’s own evaluation practices and those of the community at large.'

doi: 10.1145/3450613.3457122
url_slides: "talks/tu01_umap2021_multimethods/umap2021_tutorial_multimethods_slides.pdf"
---
